{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvLtOrx+Qps+7aY7xBbYvP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnaKarenDRIV/FinanzasUniversitarias/blob/main/_Perceptr%C3%B3n_COLAB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perceptrón - Operación OR\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Entradas y salidas esperadas\n",
        "entradas = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
        "salidas_esperadas = np.array([0, 1, 1, 1])\n",
        "\n",
        "# Inicializamos pesos y bias con valores aleatorios\n",
        "pesos = np.random.rand(2)\n",
        "bias = np.random.rand(1)\n",
        "tasa_aprendizaje = 0.1\n",
        "\n",
        "# Función de activación (step)\n",
        "def activacion(x):\n",
        "    return 1 if x >= 0 else 0\n",
        "\n",
        "# Entrenamiento del perceptrón\n",
        "for epoca in range(10):\n",
        "    for i in range(len(entradas)):\n",
        "        x = entradas[i]\n",
        "        salida_deseada = salidas_esperadas[i]\n",
        "        salida_obtenida = activacion(np.dot(x, pesos) + bias)\n",
        "\n",
        "        # Regla de actualización\n",
        "        error = salida_deseada - salida_obtenida\n",
        "        pesos = pesos + tasa_aprendizaje * error * x\n",
        "        bias = bias + tasa_aprendizaje * error\n",
        "\n",
        "print(\"Pesos finales:\", pesos)\n",
        "print(\"Bias final:\", bias)\n",
        "\n",
        "# Prueba del perceptrón entrenado\n",
        "print(\"\\nResultados finales:\")\n",
        "for i in range(len(entradas)):\n",
        "    x = entradas[i]\n",
        "    salida = activacion(np.dot(x, pesos) + bias)\n",
        "    print(f\"Entrada: {x}, Salida: {salida}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOjV8xeKBqDq",
        "outputId": "bb33e385-9285-4ccd-8a46-f71238d7ce74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pesos finales: [0.82715177 0.59990907]\n",
            "Bias final: [-0.07848795]\n",
            "\n",
            "Resultados finales:\n",
            "Entrada: [0 0], Salida: 0\n",
            "Entrada: [0 1], Salida: 1\n",
            "Entrada: [1 0], Salida: 1\n",
            "Entrada: [1 1], Salida: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicación\n",
        "\n",
        "La neurona aprende los pesos para que las salidas coincidan con la tabla lógica del OR.\n",
        "Durante cada iteración:\n",
        "\n",
        "Calcula la salida actual con los pesos.\n",
        "\n",
        "Compara con la salida esperada.\n",
        "\n",
        "Ajusta los pesos según el error.\n",
        "\n",
        "Al finalizar, el perceptrón es capaz de devolver 1 si al menos una entrada es 1."
      ],
      "metadata": {
        "id": "mEFfHAYWBmRF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYHxl9zsBEDg",
        "outputId": "f98b7bc8-7569-4428-95e9-38fc20b31b42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Peso final: [-0.22984184]\n",
            "Bias final: [0.1979311]\n",
            "\n",
            "Resultados finales:\n",
            "Entrada: [0], Salida: 1\n",
            "Entrada: [1], Salida: 0\n"
          ]
        }
      ],
      "source": [
        "# Perceptrón - Operación NOT\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Entradas y salidas esperadas\n",
        "entradas = np.array([[0], [1]])\n",
        "salidas_esperadas = np.array([1, 0])\n",
        "\n",
        "# Inicializamos pesos y bias\n",
        "pesos = np.random.rand(1)\n",
        "bias = np.random.rand(1)\n",
        "tasa_aprendizaje = 0.1\n",
        "\n",
        "# Función de activación (step)\n",
        "def activacion(x):\n",
        "    return 1 if x >= 0 else 0\n",
        "\n",
        "# Entrenamiento del perceptrón\n",
        "for epoca in range(10):\n",
        "    for i in range(len(entradas)):\n",
        "        x = entradas[i]\n",
        "        salida_deseada = salidas_esperadas[i]\n",
        "        salida_obtenida = activacion(np.dot(x, pesos) + bias)\n",
        "\n",
        "        # Actualización de pesos y bias\n",
        "        error = salida_deseada - salida_obtenida\n",
        "        pesos = pesos + tasa_aprendizaje * error * x\n",
        "        bias = bias + tasa_aprendizaje * error\n",
        "\n",
        "print(\"Peso final:\", pesos)\n",
        "print(\"Bias final:\", bias)\n",
        "\n",
        "# Prueba del perceptrón entrenado\n",
        "print(\"\\nResultados finales:\")\n",
        "for i in range(len(entradas)):\n",
        "    x = entradas[i]\n",
        "    salida = activacion(np.dot(x, pesos) + bias)\n",
        "    print(f\"Entrada: {x}, Salida: {salida}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicación\n",
        "\n",
        "Aquí el perceptrón tiene una sola entrada.\n",
        "Durante el entrenamiento, aprende que:\n",
        "\n",
        "Si la entrada es 0 → la salida debe ser 1\n",
        "\n",
        "Si la entrada es 1 → la salida debe ser 0\n",
        "\n",
        "Después de ajustar los pesos, el perceptrón invierte la entrada, cumpliendo la función NOT."
      ],
      "metadata": {
        "id": "2FIBjb0DBUy9"
      }
    }
  ]
}